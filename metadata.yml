Identifier: eos2be8
Slug: mole-embeddings
Status: In progress
Title: MolE molecular embeddings
Description: MolE is a foundation model for chemistry developed by Recursion. It combines
  geometric deep learning with transformers, to learn a meaningful representation
  of molecules. MolE leverages extensive labeled and unlabeled datasets in two pretraining
  steps. First it follows a novel self-supervised strategy using the graph representation
  of ~842 million molecules designed to properly learn to represent chemical structures.
  It is followed by a massive multi-task training to assimilate biological information.
Deployment:
  - Local
Source: Local
Source Type: External
Task: Annotation
Subtask: Featurization
Input: 
  - Compound
Input Dimension: 1
Output: Value
Output Dimension: 1
Output Consistency: Fixed
Interpretation: 'The output of this template model should be interpreted like this.'
Tag:
  - Embedding
Biomedical Area:
  - Any
Target Organism:
  - Not Applicable
Publication Type: Peer reviewed
Publication Year: 2025
Publication: https://www.nature.com/articles/s41467-024-53751-y
Source Code: https://github.com/recursionpharma/mole_public
License: MIT
